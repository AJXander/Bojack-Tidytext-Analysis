---
title: "Bojack SRT"
author: "Baldwin - 182491"
date: "21 February 2018"
output: 
  html_document:
    theme: journal
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tidytext)
library(subtools)
library(magrittr)
library(knitr)
library(ggthemes)
theme_set(theme_economist())
```

Using Francois Keck's `subtools` and the  `write_excel_csv` function, I am able to create a readable CSV file containing a line-by-line breakdown of the episode.


### n.b. there is an outstanding error that if two characters speak simultaneously, the text is preceded by a hyphen. This throws an error in Excel by default.
Solution: Replace hyphens with an alternative character?


# Objective

*Text Analysis of the Bojack Horseman TV Show*

Working from the principles learned in Tidy Text Mining and "Working with Unstructured Text Data", the purpose of this exercise is to analyse the use of language in Bojack Horseman. This will be done in several stages:

* Consider the frequency of language used and visualise the sentiments across individual episodes, across each series, and the show as a whole. This could indicate that there is a general emotional arc to each episode, or each season.
* Carry out TF-IDF analysis to identify language that makes each season distinct.
* Create a graph model of the dialogue to show how words tend to be connected

_Tidy Text analysis alone can offer a relatively shallow analysis of the show based on SRT subtitles. However, additional research can unlock further possibilities._

* Using the SRT files, manually record speakers and listeners for individual lines of dialogue and conversations.
* Calculate summary statistics, e.g. number of interactions between main characters per episode, etc.
* Analyse the sentiment of conversations between characters and visualise to determine if the sentiment tends to vary over time.



```{r Import echo=False}

s1 <- read.subtitles.season("Bojack SRT/Bojack S1 SRT/") %>% subDataFrame()
s2 <- read.subtitles.season("Bojack SRT/Bojack S2 SRT/") %>% subDataFrame()
s3 <- read.subtitles.season("Bojack SRT/Bojack S3 SRT/") %>% subDataFrame()
s4 <- read.subtitles.season("Bojack SRT/Bojack S4 SRT/") %>% subDataFrame()
all_s <- rbind(s1,s2,s3,s4)
all_s %<>% filter(!str_detect(.$Text, "7ed")) # Removes the sync information.
all_s %<>% filter(!str_detect(.$Text, "[0-9]x")) # Removes episode title


```

At this stage, the dataframe can be exported as a CSV file with each line of dialogue.
The speakers and listeners can then be manually recorded. This will be done and the work imported later for the second stage of analysis.


# Tidytext Analysis


```{r}
tidy_bojack <- all_s %>% unnest_tokens(word, Text)
data("stop_words")
tidy_bojack %<>% anti_join(stop_words, by = "word")
#TODO - Add additional words
```


### Season Word Frequency

```{r}
tidy_bojack %>% mutate(season = factor(season, levels = c("Bojack S1 SRT", "Bojack S2 SRT", "Bojack S3 SRT", "Bojack S4 SRT"))) %>%
  group_by(season) %>% count(season,word, sort = T) %>% arrange(season, desc(n)) %>% top_n(10) %>%
  ggplot(aes(reorder(word,n), n, fill = season)) +
        geom_bar(stat = "identity") +
        coord_flip() +
        facet_wrap(~season, scales = "free_y") +labs(x = NULL) +
        guides(fill = FALSE) +
        scale_fill_brewer(palette = "Set1")
```

_Honestly, I have no idea why I can't order these properly, even copying code where it works. They seem to be ordered by absolute values in the dataset despite being grouped by season. The below charts show the actual order._


```{r}
tidy_bojack %>% filter(season_num == 1) %>% count(word, sort = T) %>% top_n(10) %>% ggplot(aes(reorder(word,n), n)) + geom_col() + coord_flip() + guides(fill = F)
```

```{r}
tidy_bojack %>% filter(season_num == 2) %>% count(word, sort = T) %>% top_n(10) %>% ggplot(aes(reorder(word,n), n)) + geom_col() + coord_flip() + guides(fill = F)
```

```{r}
tidy_bojack %>% filter(season_num == 3) %>% count(word, sort = T) %>% top_n(10) %>% ggplot(aes(reorder(word,n), n)) + geom_col() + coord_flip() + guides(fill = F)
```


```{r}
tidy_bojack %>% filter(season_num == 4) %>% count(word, sort = T) %>% top_n(10) %>% ggplot(aes(reorder(word,n), n)) + geom_col() + coord_flip() + guides(fill = F)
```

```{r}
tf_idf_df <- tidy_bojack %>% 
        count(season, word, sort = TRUE) %>%
        bind_tf_idf(word, season, n)

tf_idf_df %>% mutate(word = reorder(word, n)) %>% top_n(10) %>% ggplot(aes(x=word, y=tf_idf, fill = season)) + geom_col() + coord_flip()
```


## TODO

Remove hesitations and "na"

* Sentiment Analysis
* Interaction Analysis
* Word Networks